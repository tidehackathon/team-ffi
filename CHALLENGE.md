# Informasjon om oppgaven
*Samlet opp fra forskjellige TIDEPedia sider, en del er nok gjentatt flere ganger*
## Disinformation Analyser

Design and develop content analysis tools capable of news channel monitoring provided in forms of social media & communicators monitoring. The main aim of the tool is to identify & recognise specific content which meets criteria designed and provided by POL Cyber Command analysts.

The most important aspect of the tool will be the ability to recognise words, sentences or even paragraphs of articles that can be evaluated and assessed from the disinformation perspective. The data sources will be provided and prepared by POL Cyber Command experts – it will be collected from past disinformation campaigns (e.g. messages from the Telegram communicator in JSON format, tweets and other messages from Facebook Messenger etc.).

The tool will not be designed to identify complex disinformation campaigns.

The challenge will also encourage implementation of AI tools for contextual analysis of natural language and other methods utilised for semantic analysis. Develop, Integrate, Chain as much available tools, libraries in order to invent an analytical tool capable of disinformation event recognition.

What will be valued: the precision of content identification is a key feature; however, the flexibility of mechanisms configuration, as well as the range of monitored content will be honored.

The tool should be based on open-source and/or proprietary software components and could be e.g. a server-deployed application, capable of disinformation event identification, providing an analytical - visualisation portal.

The task will be conducted in English only.

------
**Problem:** Disinformation is everywhere. NATO’s definition of disinformation is the “deliberate creation and dissemination of false and/or manipulated information with the intent to deceive and/or mislead.” In an Alliance of 30 nations, disinformation seeks to deepen divisions within and between nations, and to undermine citizens’ trust of elected government through malicious cyber activities. Since the illegal Russian annex of Crimea in 2014 and the illegal Russian invasion of Ukraine in 2023, NATO is actively countering a significant increase in disinformation and propaganda.

**Challenge:**: Teams will demonstrate precise yet flexible content analysis tools capable of news channel and social media monitoring. The main aim of the tool is to identify content which meets criteria provided by POL Cyber Command analysts; including words, sentences or paragraphs of articles that can be evaluated from a disinformation perspective. Implementation of AI tools for contextual analysis of natural language and other methods utilised for semantic analysis are encouraged. Demonstrations must be based on open-source software components and could be e.g. a server-deployed application, capable of disinformation event identification, providing an analytical - visualisation portal.

**Impact:** Enhanced disinformation analysis would support NATO’s intensified efforts to strengthen its ability to prepare for, deter, and defend against hybrid tactics that seek to undermine our security and societies.

----

### What	
Disinformation is false or misleading content that is disseminated with the intention of deceiving people. The spread of disinformation can have a number of damaging consequences, such as threats to our safety, economies, health and many more.

Widespread disinformation campaigns in social media and chat messaging applications may pose a serious challenge to NATO countries and require a coordinated response that can not be achieved without appropriate tools and techniques allowing to recognize them.

### Who	
Who Benefits and how:

NATO and member countries’ digital media monitoring institutions. Institutions responsible for StratCom and InfoOps both military and intelligence, working with information, its interpretation and infospace manipulation issues.

Thinktanks, NGO’s, news companies monitoring specific media sources in search for symptoms of disinformation, deepfakes and other multimedia content used for manipulation.

OSINT Freelancers and Analysts gathering intel on current political, military events, providing articles and podcasts shared as referencial data for further analysis.

### Impact	
Correctly recognising and analysing disinformation content may prevent its further spread and may eventually increase situational awareness for decision makers.

### Outcome	
Developed tools should work as a server-deployed tool capable of disinformation event identification, and a analytical - visualisation portal.

Methods, algorithms, models need to be calibrated and their capabilities explained on the given data samples.

### Data	
Participants will receive several data sets containing data collected from different online sources of information which were made for the purposes of scientific research and focus on ongoing Russian-Ukrainian war.

The content of proposed data sets is mostly in English and may contain information from reliable sources as well as disinformation. In addition, files may include metadata such as dates, links, sharing stats, users info and some more which can be used to develop the final solution. All data files will occupy about 4GB of disk space.

----

### Prerequisites	
The teams will be working on real media sources identifying content and pointing out (recognising) the disinformation messages (textual and/or graphic content) with the analytical explanation provided by their tool. It is possible to collect scraps of messages in form of parsable files and work offline, however the more tuneable the tools will be to work with real API’s or parse real media portals the more points they will receive.

**Examples**

https://www.upgrad.com/blog/fake-news-detection-in-machine-learning/

https://towardsdatascience.com/machine-learning-tackles-the-fake-news-problem-c3fa75549e52

**References**	

https://stratcomcoe.org/

https://instituteforpr.org/10-ways-to-spot-disinformation/

**Resources**

https://github.com/KaiDMML/FakeNewsNet

https://www.rand.org/research/projects/truth-decay/fighting-disinformation/search.html
